# ğŸš€ x402 MCP AI Agent - AgentCore Mastra

## Overview

A cutting-edge Next.js application showcasing AI agent integration with x402 MCP (Model Context Protocol) server for retrieving real-time data from resource servers. Built for JAWS UG AI Builders Day demonstration.

### âœ¨ Key Features

- ğŸ¤– **Dual AI Model Support**: Switch between Amazon Bedrock Nova Lite and Google Gemini 2.0 Flash
- ğŸ”— **MCP Integration**: Seamless AI-to-server communication via Model Context Protocol  
- ğŸ¨ **Modern UI/UX**: Glassmorphism design with smooth animations and transitions
- ğŸ“± **PWA Ready**: Progressive Web App with offline capabilities
- âš¡ **Real-time Data**: Instant resource server data retrieval through AI agents

## Setup

1. Install dependencies

```bash
pnpm i
```

2. Configure environment variables in `.env`:

```env
# Amazon Bedrock Configuration
AMAZOM_BEDROCK_API_KEY=your_bedrock_api_key
AWS_REGION=ap-northeast-1

# Google Gemini Configuration (Optional, but recommended)
GOOGLE_API_KEY=your_google_api_key

# x402 MCP Server Configuration (for local development)
PRIVATE_KEY=your_private_key
RESOURCE_SERVER_URL=your_resource_server_url
ENDPOINT_PATH=your_endpoint_path
```

3. Run Next.js

```bash
pnpm dev
```

## Features

### AI Agent with MCP Tool Integration

The application uses Mastra AI agents that can call MCP tools to fetch real-time data from resource servers.

#### Model Selection

You can choose between two AI models:

1. **Amazon Nova Lite** (Default)
   - Fast and cost-effective
   - âš ï¸ May have limitations with complex tool calling
   - Best for simple queries

2. **Google Gemini 2.0 Flash** (Recommended)
   - More reliable tool calling
   - Better at following instructions
   - Recommended for production use

#### Usage

1. Open the application in your browser
2. Select your preferred AI model (toggle checkbox for Gemini)
3. Enter a prompt like "å¤©æ°—ã‚’æ•™ãˆã¦" or "ãƒªã‚½ãƒ¼ã‚¹ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã¦"
4. The AI agent will call the x402 MCP tool and return formatted results

### Known Issues & Solutions

#### Amazon Nova Lite Tool Calling Issues

**Problem**: The Amazon Nova Lite model may return incomplete responses when attempting to call tools, resulting in truncated output like `<thinking>...`.

**Solution**: 
- Use the Gemini model toggle for better reliability
- The application now includes automatic detection of incomplete responses
- Clear error messages guide users to switch models if needed

**Root Cause**: This is a known limitation of the Amazon Nova Lite model in handling complex tool calling scenarios with MCP servers.

### Error Handling

The application includes robust error handling:

- Detects incomplete AI responses
- Validates tool call execution
- Provides clear error messages in Japanese
- Suggests alternative models when issues occur

## Architecture

```
User Input â†’ Weather Component â†’ Server Action â†’ Mastra Agent â†’ x402 MCP Client â†’ Resource Server
                                                    â†“
                                            (Bedrock or Gemini)
                                                    â†“
                                              Formatted Response
```

## Tech Stack

- **Frontend**: Next.js 15, React 19, TypeScript
- **UI**: shadcn/ui, Tailwind CSS
- **AI Framework**: Mastra (AI agent orchestration)
- **AI Models**: 
  - Amazon Bedrock (Nova Lite)
  - Google Gemini 2.0 Flash
- **Protocol**: Model Context Protocol (MCP)
- **PWA**: Progressive Web App support

## Development

### File Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ actions.ts          # Server actions for AI agent calls
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ Weather.tsx     # Main UI component with model selection
â”‚   â””â”€â”€ page.tsx            # Home page
â”œâ”€â”€ mastra/
â”‚   â”œâ”€â”€ index.ts            # Mastra instance management
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ index.ts        # x402 Agent configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ index.ts        # AI model definitions
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ x402.ts         # x402 MCP client configuration
```

### Adding New MCP Tools

1. Define your MCP server in `src/mastra/tools/`
2. Update the agent instructions in `src/mastra/agents/index.ts`
3. Test with both Bedrock and Gemini models

## Troubleshooting

### Tools Not Being Called

1. Check MCP server logs for connection issues
2. Verify environment variables are set correctly
3. Try switching to Gemini model
4. Check browser console for detailed error messages

### Incomplete Responses

If you see responses like `<thinking>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¤©æ°—æƒ…å ±ã‚’...`, this indicates:
- The AI model stopped generating before completing the tool call
- Switch to Gemini model for better reliability
- Check if the MCP server is accessible

## Contributing

When making changes:
1. Test with both AI models
2. Ensure error handling is comprehensive
3. Update this README with any new features or known issues
4. Follow the coding guidelines in `AGENTS.md`
